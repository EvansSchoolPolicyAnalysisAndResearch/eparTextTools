---
title: "Scraping Structured Documents"
author: "Ryan P Scott"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Scraping Structured Documents}
  %\VignetteEngine{knitr::knitr}
  %\VignetteEncoding{UTF-8}
---

Structured docments provide the opportunity to move beyond adopting all text strings for text analysis. Because structured documents such as forms possess entry areas that specify what is supposedly included in the following lines, we can utilize that structure to help define features of the text or characteristics of the documents. 

In terms of structured documents, there are multple kinds a user may run across. First of all, a structured PDF may have OCR labelled text that is in a similar location across a wide body of documents. These are among the more complicated documents to code as one has to rely on characters either being recognized the same across a range of responses or the text information must remained stored in a similar manner across the corpus. Word documents can have structured form fields--this is much less of a problem for extracting data, and we can rely on commmon tools such as Microsoft Access to batch process results. However, this vignette demonstrates how to utilize R to extract necessary information from form fields rapidly by visually assessing the form document and deciding what information is needed for a database.

#Demonstration
Here, we load agendas from some meetings from the state of Colorado. These tools are mostly built for word files so that's what we demonstrate here.
```{r}
tfiles<-list.files("~/CRO_form_demo",full.names=T)
tfiles<-tfiles[str_detect(tolower(tfiles),"docx")]
```
Word files area really just xml files. To see the contents of a file, you can use the "docx_table_view()" command.

```{r}
head(docx_table_view(tfiles[1], export_frame=T,showView=F))
```

We can use that structured information to select common elements. When we are unsure what exactly we need from each document but we know what text comes before and after, we can use the cell_extractor function to then select relevent text. For example, if we want the dates from the files above, we would select "CO Resiliency Framework Services Project" and "SUMMARY REPORT" as brackets.

```{r}
cell_extractor(docx_table_view(tfiles[1],export_frame=T,showView=F)$content,"CO Resiliency","SUMMARY")
```

This can then easily be wrapped through documents.

```{r}
sapply(tfiles, function(X) tryCatch({cell_extractor(docx_table_view(X,export_frame=T,showView=F)$content,"CO Resiliency","SUMMARY")},error=function(e) {NA}))
```

Based on the warning, se can see this worked for most of our documents but not all of our documents. One could use the table view command to inspect the files, but we could also use the document cluster command to see how our documents/forms may differ and if that set is meaningfully different. If you had 10000 forms, you obviously couldnt look at them all. 

```{r}
formcluster(tfiles)
```

We might notice that the first four documents are generally somewhat different from the 5th through 11th documents, suggesting we need to do more to think about how to analyze these forms.

```{r, eval=F}
docx_table_view(tfiles[8])
docx_table_view(tfiles[1])
```

